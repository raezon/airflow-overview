# ğŸª Pluto : Explication DÃ©taillÃ©e d'Airflow

## ğŸ¯ 1. DAG (Directed Acyclic Graph) - La Recette ComplÃ¨te

### ğŸ“š Explication DÃ©taillÃ©e
Un **DAG** est le cÅ“ur d'Airflow. Imaginez-le comme une **recette de cuisine complÃ¨te** :
- **Directed** : Les Ã©tapes ont un ordre prÃ©cis (on ne met pas le gÃ¢teau au four avant de mÃ©langer les ingrÃ©dients)
- **Acyclic** : Pas de boucles infinies (on ne peut pas revenir en arriÃ¨re indÃ©finiment)
- **Graph** : ReprÃ©sentation visuelle des dÃ©pendances entre les tÃ¢ches

**CaractÃ©ristiques principales :**
- `dag_id` : Nom unique de votre recette
- `schedule_interval` : FrÃ©quence d'exÃ©cution (quotidienne, horaire, etc.)
- `start_date` : Date de dÃ©but de la recette
- `catchup` : Rattrapage des exÃ©cutions manquÃ©es ou non

### ğŸ³ Illustration Culinaire
```python
from airflow import DAG
from datetime import datetime, timedelta

# Notre recette de pain perdu
with DAG(
    dag_id="recette_pain_perdu",           # Nom de la recette
    description="Recette familiale de pain perdu",
    start_date=datetime(2024, 1, 1),       # Date de crÃ©ation de la recette
    schedule_interval="@daily",            # On peut en faire tous les jours
    catchup=False,                         # On ne rattrape pas les jours manquÃ©s
    default_args={
        'owner': 'chef_pluto',             # Le chef responsable
        'retries': 2,                      # Si Ã§a rate, on rÃ©essaie 2 fois
        'retry_delay': timedelta(minutes=5) # On attend 5 min entre chaque essai
    },
    tags=['breakfast', 'french', 'family'] # Tags pour retrouver la recette
) as dag:
    
    # Ici viendront toutes les Ã©tapes de la recette
    print("ğŸ“– Recette de pain perdu chargÃ©e!")
```

### ğŸ”§ Code DÃ©taillÃ© avec Explications
```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import pandas as pd

# Arguments par dÃ©faut pour TOUTES les tÃ¢ches du DAG
default_args = {
    'owner': 'data_team',           # Qui est responsable
    'depends_on_past': False,       # Ne dÃ©pend pas des runs prÃ©cÃ©dents
    'email': ['alert@mycompany.com'], # Emails pour les alertes
    'email_on_failure': True,       # Email si Ã©chec
    'email_on_retry': False,        # Pas d'email sur les retry
    'retries': 3,                   # Nombre de tentatives en cas d'Ã©chec
    'retry_delay': timedelta(minutes=10) # DÃ©lai entre les retry
}

# CrÃ©ation du DAG avec tous ses paramÃ¨tres
with DAG(
    dag_id='data_processing_pipeline',
    default_args=default_args,
    description='Pipeline de traitement des donnÃ©es clients',
    schedule_interval=timedelta(hours=1),  # Toutes les heures
    start_date=datetime(2024, 1, 1, 0, 0), # 1er Janvier 2024 Ã  minuit
    end_date=datetime(2024, 12, 31, 23, 59), # Jusqu'au 31 DÃ©cembre
    catchup=True,                    # Rattrape les exÃ©cutions manquÃ©es
    max_active_runs=3,               # Maximum 3 exÃ©cutions simultanÃ©es
    concurrency=10,                  # Maximum 10 tÃ¢ches simultanÃ©es
    tags=['data', 'processing', 'etl']
) as dag:
    
    def log_dag_start():
        """Fonction exÃ©cutÃ©e au dÃ©but du DAG"""
        print(f"ğŸš€ DÃ©but du pipeline Ã  {datetime.now()}")
        return "DAG dÃ©marrÃ© avec succÃ¨s"
    
    start_task = PythonOperator(
        task_id='demarrage_pipeline',
        python_callable=log_dag_start
    )
```

---

## ğŸ¯ 2. TASKS - Les Ã‰tapes Individuelles

### ğŸ“š Explication DÃ©taillÃ©e
Une **Task** reprÃ©sente une **Ã©tape individuelle** dans votre DAG. Chaque task :
- Est une unitÃ© de travail indÃ©pendante
- Peut Ãªtre exÃ©cutÃ©e sur diffÃ©rents workers
- A un Ã©tat (success, failed, running, etc.)
- Peut avoir des dÃ©pendances avec d'autres tasks

**Types d'opÃ©rateurs principaux :**
- `PythonOperator` : ExÃ©cute une fonction Python
- `BashOperator` : ExÃ©cute une commande shell
- `EmailOperator` : Envoie un email
- `Sensor` : Attend qu'une condition soit remplie

### ğŸ³ Illustration Culinaire
```python
from airflow.operators.python import PythonOperator

def preparer_pain():
    """Couper le pain en tranches"""
    print("ğŸ Je coupe 6 tranches de pain rassis")
    return "pain_coupe"

def preparer_lait_oeufs():
    """PrÃ©parer le mÃ©lange lait/Å“ufs"""
    print("ğŸ¥› Je mÃ©lange 2 Å“ufs avec 25cl de lait")
    print("ğŸ¶ J'ajoute une pincÃ©e de vanille et de cannelle")
    return "melange_pret"

def tremper_pain(**context):
    """Tremper le pain dans le mÃ©lange"""
    # RÃ©cupÃ¨re le rÃ©sultat de la tÃ¢che prÃ©cÃ©dente
    melange = context['task_instance'].xcom_pull(task_ids='preparer_lait_oeufs')
    pain = context['task_instance'].xcom_pull(task_ids='preparer_pain')
    
    print(f"ğŸ«— Je trempe {pain} dans {melange}")
    return "pain_trempe"

def cuire_pain(**context):
    """Cuire le pain Ã  la poÃªle"""
    pain_trempe = context['task_instance'].xcom_pull(task_ids='tremper_pain')
    print(f"ğŸ³ Je fais cuire {pain_trempe} Ã  la poÃªle beurrÃ©e")
    print("ğŸ”¥ Cuisson 3 minutes de chaque cÃ´tÃ©")
    return "pain_perdu_cuit"

# CrÃ©ation des tÃ¢ches
etape1 = PythonOperator(
    task_id="preparer_pain",
    python_callable=preparer_pain
)

etape2 = PythonOperator(
    task_id="preparer_lait_oeufs", 
    python_callable=preparer_lait_oeufs
)

etape3 = PythonOperator(
    task_id="tremper_pain",
    python_callable=tremper_pain
)

etape4 = PythonOperator(
    task_id="cuire_pain",
    python_callable=cuire_pain
)
```

### ğŸ”§ Code DÃ©taillÃ© avec Gestion d'Erreurs
```python
from airflow.operators.python import PythonOperator
from airflow.exceptions import AirflowException
import requests
import json

def telecharger_donnees_api():
    """TÃ©lÃ©charge des donnÃ©es depuis une API avec gestion d'erreur"""
    try:
        print("ğŸ“¡ Connexion Ã  l'API...")
        response = requests.get(
            'https://api.mon-service.com/donnees',
            timeout=30,  # Timeout de 30 secondes
            headers={'Authorization': 'Bearer mon-token'}
        )
        
        # VÃ©rifier le statut HTTP
        if response.status_code != 200:
            raise AirflowException(f"Erreur API: {response.status_code}")
        
        data = response.json()
        print(f"âœ… DonnÃ©es tÃ©lÃ©chargÃ©es: {len(data)} enregistrements")
        return data
        
    except requests.exceptions.Timeout:
        raise AirflowException("Timeout de l'API - trop long Ã  rÃ©pondre")
    except requests.exceptions.ConnectionError:
        raise AirflowException("Impossible de se connecter Ã  l'API")
    except json.JSONDecodeError:
        raise AirflowException("RÃ©ponse API invalide - JSON corrompu")

def traiter_donnees(**context):
    """Traite les donnÃ©es tÃ©lÃ©chargÃ©es"""
    try:
        # RÃ©cupÃ©rer les donnÃ©es de la tÃ¢che prÃ©cÃ©dente
        donnees_brutes = context['task_instance'].xcom_pull(task_ids='telecharger_donnees')
        
        if not donnees_brutes:
            raise AirflowException("Aucune donnÃ©e Ã  traiter")
        
        print(f"ğŸ”§ Traitement de {len(donnees_brutes)} enregistrements...")
        
        # Exemple de traitement
        donnees_traitees = []
        for item in donnees_brutes:
            # Nettoyage des donnÃ©es
            item_propre = {
                'id': item.get('id'),
                'nom': item.get('name', '').strip().title(),
                'valeur': float(item.get('value', 0)),
                'date_creation': item.get('created_at')
            }
            donnees_traitees.append(item_propre)
        
        print(f"âœ… DonnÃ©es traitÃ©es: {len(donnees_traitees)} enregistrements nettoyÃ©s")
        return donnees_traitees
        
    except Exception as e:
        raise AirflowException(f"Erreur lors du traitement: {str(e)}")

def sauvegarder_resultats(**context):
    """Sauvegarde les rÃ©sultats finaux"""
    donnees_finales = context['task_instance'].xcom_pull(task_ids='traiter_donnees')
    
    if donnees_finales:
        # Sauvegarde dans un fichier (dans un vrai cas, ce serait une base de donnÃ©es)
        with open('/tmp/donnees_traitees.json', 'w') as f:
            json.dump(donnees_finales, f, indent=2)
        
        print(f"ğŸ’¾ DonnÃ©es sauvegardÃ©es: {len(donnees_finales)} enregistrements")
        return f"sauvegarde_reussie_{len(donnees_finales)}_items"
    else:
        raise AirflowException("Aucune donnÃ©e Ã  sauvegarder")

# CrÃ©ation des tÃ¢ches avec gestion d'erreur
telechargement = PythonOperator(
    task_id='telecharger_donnees',
    python_callable=telecharger_donnees_api,
    retries=2,  # 2 tentatives supplÃ©mentaires en cas d'Ã©chec
    retry_delay=timedelta(minutes=1)
)

traitement = PythonOperator(
    task_id='traiter_donnees',
    python_callable=traiter_donnees,
    retries=1
)

sauvegarde = PythonOperator(
    task_id='sauvegarder_resultats',
    python_callable=sauvegarder_resultats
)
```

---

## ğŸ¯ 3. DÃ‰PENDANCES - L'Ordre des OpÃ©rations

### ğŸ“š Explication DÃ©taillÃ©e
Les **dÃ©pendances** dÃ©finissent **l'ordre d'exÃ©cution** des tÃ¢ches. C'est comme dire :
- "Il faut mÃ©langer les ingrÃ©dients AVANT de mettre au four"
- "La dÃ©coration se fait APRÃˆS la cuisson"

**Deux syntaxes possibles :**
- **OpÃ©rateur bitshift** : `tache1 >> tache2 >> tache3`
- **MÃ©thodes** : `tache2.set_upstream(tache1)`

### ğŸ³ Illustration Culinaire
```python
# Notre recette de cookies avec dÃ©pendances complexes

def prechauffer_four():
    print("ğŸ”¥ PrÃ©chauffer le four Ã  180Â°C")

def melanger_ingredients():
    print("ğŸ¥„ MÃ©langer beurre, sucre, Å“ufs")
    print("ğŸŒ¾ Ajouter farine et pÃ©pites de chocolat")

def former_cookies():
    print("ğŸ‘ Former des boules de pÃ¢te")
    return "12_boules_pretes"

def cuire_cookies(**context):
    boules = context['task_instance'].xcom_pull(task_ids='former_cookies')
    print(f"ğŸª Enfourner {boules} pendant 12 minutes")
    return "cookies_cuits"

def laisser_refroidir(**context):
    cookies = context['task_instance'].xcom_pull(task_ids='cuire_cookies')
    print(f"â„ï¸ Laisser refroidir {cookies} sur une grille")

# CrÃ©ation des tÃ¢ches
prechauffage = PythonOperator(task_id="prechauffer_four", python_callable=prechauffer_four)
melange = PythonOperator(task_id="melanger_ingredients", python_callable=melanger_ingredients)
formation = PythonOperator(task_id="former_cookies", python_callable=former_cookies)
cuisson = PythonOperator(task_id="cuire_cookies", python_callable=cuire_cookies)
refroidissement = PythonOperator(task_id="laisser_refroidir", python_callable=laisser_refroidir)

# DÃ©finition des dÃ©pendances - METHODE 1: OpÃ©rateur bitshift
prechauffage >> melange >> formation >> cuisson >> refroidissement

# METHODE 2: MÃ©thodes set_upstream/set_downstream (Ã©quivalent)
# formation.set_upstream(melange)
# cuisson.set_upstream(formation)
# refroidissement.set_upstream(cuisson)
```

### ğŸ”§ Code DÃ©taillÃ© avec DÃ©pendances Complexes
```python
from airflow.operators.python import PythonOperator
from airflow.operators.dummy import DummyOperator

# TÃ¢ches de dÃ©but/fin
debut = DummyOperator(task_id='debut_pipeline')
fin = DummyOperator(task_id='fin_pipeline')

# TÃ¢ches parallÃ¨les
def extraire_donnees_clients():
    print("ğŸ‘¥ Extraction donnÃ©es clients...")
    return "clients_extraits"

def extraire_donnees_produits():
    print("ğŸ“¦ Extraction donnÃ©es produits...") 
    return "produits_extraits"

def extraire_donnees_ventes():
    print("ğŸ’° Extraction donnÃ©es ventes...")
    return "ventes_extraits"

extraction_clients = PythonOperator(
    task_id='extraire_clients',
    python_callable=extraire_donnees_clients
)

extraction_produits = PythonOperator(
    task_id='extraire_produits',
    python_callable=extraire_donnees_produits
)

extraction_ventes = PythonOperator(
    task_id='extraire_ventes',
    python_callable=extraire_donnees_ventes
)

# TÃ¢ches de transformation
def transformer_donnees(**context):
    clients = context['ti'].xcom_pull(task_ids='extraire_clients')
    produits = context['ti'].xcom_pull(task_ids='extraire_produits')
    ventes = context['ti'].xcom_pull(task_ids='extraire_ventes')
    
    print(f"ğŸ”¨ Transformation des donnÃ©es: {clients}, {produits}, {ventes}")
    return "donnees_transformees"

transformation = PythonOperator(
    task_id='transformer_donnees',
    python_callable=transformer_donnees
)

# TÃ¢ches de chargement
def charger_entrepot():
    print("ğŸª Chargement dans l'entrepÃ´t de donnÃ©es...")
    return "entrepot_charge"

def charger_rapports():
    print("ğŸ“Š Chargement pour les rapports...")
    return "rapports_prets"

chargement_entrepot = PythonOperator(
    task_id='charger_entrepot',
    python_callable=charger_entrepot
)

chargement_rapports = PythonOperator(
    task_id='charger_rapports',
    python_callable=charger_rapports
)

# DÃ‰PENDANCES COMPLEXES
# DÃ©but â†’ extractions (en parallÃ¨le)
debut >> [extraction_clients, extraction_produits, extraction_ventes]

# Extractions â†’ transformation
[extraction_clients, extraction_produits, extraction_ventes] >> transformation

# Transformation â†’ chargements (en parallÃ¨le)  
transformation >> [chargement_entrepot, chargement_rapports]

# Chargements â†’ fin
[chargement_entrepot, chargement_rapports] >> fin
```

---

## ğŸ¯ 4. XCOM - Ã‰change de DonnÃ©es entre TÃ¢ches

### ğŸ“š Explication DÃ©taillÃ©e
**XCom** (Cross-Communication) permet aux tÃ¢ches de **partager des donnÃ©es**. C'est comme passer un bol d'ingrÃ©dients d'un chef Ã  un autre.

**Fonctionnement :**
- `xcom_push()` : Envoyer des donnÃ©es
- `xcom_pull()` : RÃ©cupÃ©rer des donnÃ©es
- LimitÃ© Ã  ~48KB (pour les petites donnÃ©es)
- Par dÃ©faut, la valeur de retour d'une tÃ¢che est automatiquement poussÃ©e en XCom

### ğŸ³ Illustration Culinaire
```python
def chef_patissier_prepare_creme():
    """Le chef pÃ¢tissier prÃ©pare la crÃ¨me"""
    recette_creme = {
        'ingredients': ['crÃ¨me fraÃ®che', 'sucre', 'vanille'],
        'quantites': ['250ml', '50g', '1 gousse'],
        'instructions': 'Fouetter la crÃ¨me avec le sucre et la vanille'
    }
    print("ğŸ§ Chef pÃ¢tissier: Je prÃ©pare la crÃ¨me chantilly")
    return recette_creme  # Automatiquement poussÃ© en XCom

def chef_cuisinier_prepare_fruits(**context):
    """Le chef cuisinier prÃ©pare les fruits"""
    # RÃ©cupÃ¨re la recette de la crÃ¨me
    recette_creme = context['task_instance'].xcom_pull(
        task_ids='chef_patissier_prepare_creme'
    )
    
    print(f"ğŸ“ Chef cuisinier: Je vois que le pÃ¢tissier a prÃ©parÃ©: {recette_creme['ingredients']}")
    print("ğŸ“ Je coupe des fraises et des framboises pour l'accompagnement")
    
    fruits_prepares = {
        'fruits': ['fraises', 'framboises', 'myrtilles'],
        'quantite': '250g'
    }
    return fruits_prepares

def assemble_dessert(**context):
    """Assemblage final du dessert"""
    # RÃ©cupÃ¨re les prÃ©parations des deux chefs
    creme = context['ti'].xcom_pull(task_ids='chef_patissier_prepare_creme')
    fruits = context['ti'].xcom_pull(task_ids='chef_cuisinier_prepare_fruits')
    
    print("ğŸ‚ ASSEMBLAGE FINAL:")
    print(f"   - CrÃ¨me: {creme['ingredients']}")
    print(f"   - Fruits: {fruits['fruits']}")
    print("   - Dressage dans des coupes")
    
    return "dessert_assemblÃ©_et_prÃªt_Ã _servir"

# CrÃ©ation des tÃ¢ches
patissier = PythonOperator(
    task_id="chef_patissier_prepare_creme",
    python_callable=chef_patissier_prepare_creme
)

cuisinier = PythonOperator(
    task_id="chef_cuisinier_prepare_fruits",
    python_callable=chef_cuisinier_prepare_fruits
)

assembleur = PythonOperator(
    task_id="assemble_dessert",
    python_callable=assemble_dessert
)

# DÃ©pendances
patissier >> cuisinier >> assembleur
```

### ğŸ”§ Code DÃ©taillÃ© avec XCom AvancÃ©
```python
from airflow.operators.python import PythonOperator
from airflow.models import XCom

def traitement_etape_1():
    """PremiÃ¨re Ã©tape de traitement"""
    donnees_initiales = {
        'fichier_source': 'data_2024.csv',
        'nombre_lignes': 10000,
        'colonnes': ['id', 'nom', 'email', 'date_inscription'],
        'statut': 'brut'
    }
    
    # METHODE 1: Return automatique (recommandÃ©)
    return donnees_initiales

def traitement_etape_2(**context):
    """DeuxiÃ¨me Ã©tape avec rÃ©cupÃ©ration XCom"""
    # RÃ©cupÃ©ration avec diffÃ©rentes mÃ©thodes
    donnees_etape1 = context['ti'].xcom_pull(
        task_ids='traitement_etape_1',
        key='return_value'  # Valeur par dÃ©faut
    )
    
    print(f"ğŸ“¥ DonnÃ©es reÃ§ues de l'Ã©tape 1: {donnees_etape1}")
    
    # Traitement
    donnees_etape1['statut'] = 'nettoye'
    donnees_etape1['lignes_traitees'] = 9500
    donnees_etape1['lignes_erreur'] = 500
    
    # METHODE 2: Push manuel avec clÃ© personnalisÃ©e
    context['ti'].xcom_push(key='donnees_nettoyees', value=donnees_etape1)
    
    return "nettoyage_termine"

def traitement_etape_3(**context):
    """TroisiÃ¨me Ã©tape avec XCom multiple"""
    # RÃ©cupÃ©ration de plusieurs valeurs XCom
    statut_nettoyage = context['ti'].xcom_pull(task_ids='traitement_etape_2', key='return_value')
    donnees_nettoyees = context['ti'].xcom_pull(task_ids='traitement_etape_2', key='donnees_nettoyees')
    
    print(f"ğŸ“Š Statut: {statut_nettoyage}")
    print(f"ğŸ“‹ DonnÃ©es nettoyÃ©es: {donnees_nettoyees}")
    
    # Traitement final
    resultat_final = {
        'fichier_sortie': 'data_2024_traite.csv',
        'statistiques': {
            'total_lignes': donnees_nettoyees['nombre_lignes'],
            'lignes_valides': donnees_nettoyees['lignes_traitees'],
            'taux_reussite': (donnees_nettoyees['lignes_traitees'] / donnees_nettoyees['nombre_lignes']) * 100
        },
        'date_traitement': str(context['execution_date'])
    }
    
    # Push multiple avec diffÃ©rentes clÃ©s
    context['ti'].xcom_push(key='resultat_final', value=resultat_final)
    context['ti'].xcom_push(key='fichier_sortie', value=resultat_final['fichier_sortie'])
    context['ti'].xcom_push(key='statistiques', value=resultat_final['statistiques'])
    
    return resultat_final

def generer_rapport(**context):
    """GÃ©nÃ¨re un rapport Ã  partir de tous les XCom"""
    # RÃ©cupÃ©ration de TOUS les XCom de l'exÃ©cution
    resultat_final = context['ti'].xcom_pull(task_ids='traitement_etape_3', key='resultat_final')
    fichier_sortie = context['ti'].xcom_pull(task_ids='traitement_etape_3', key='fichier_sortie')
    stats = context['ti'].xcom_pull(task_ids='traitement_etape_3', key='statistiques')
    
    print("ğŸ“ˆ RAPPORT DE TRAITEMENT:")
    print(f"   Fichier: {fichier_sortie}")
    print(f"   Statistiques: {stats}")
    print(f"   RÃ©sultat complet: {resultat_final}")
    
    return "rapport_gÃ©nÃ©rÃ©"

# CrÃ©ation du pipeline
etape1 = PythonOperator(task_id='traitement_etape_1', python_callable=traitement_etape_1)
etape2 = PythonOperator(task_id='traitement_etape_2', python_callable=traitement_etape_2)
etape3 = PythonOperator(task_id='traitement_etape_3', python_callable=traitement_etape_3)
rapport = PythonOperator(task_id='generer_rapport', python_callable=generer_rapport)

# DÃ©pendances
etape1 >> etape2 >> etape3 >> rapport
```

---

## ğŸ¯ 5. SENSORS - Attente d'Ã‰vÃ©nements

### ğŸ“š Explication DÃ©taillÃ©e
Les **Sensors** sont des tÃ¢ches spÃ©ciales qui **attendent qu'une condition soit remplie** avant de continuer. C'est comme attendre que l'eau bout avant d'ajouter les pÃ¢tes.

**Types courants :**
- `FileSensor` : Attend qu'un fichier existe
- `ExternalTaskSensor` : Attend qu'une autre tÃ¢che soit terminÃ©e
- `PythonSensor` : Condition personnalisÃ©e en Python

### ğŸ³ Illustration Culinaire
```python
from airflow.sensors.filesystem import FileSensor
from airflow.sensors.python import PythonSensor
from datetime import datetime, timedelta

def attendre_livraison_ingredients():
    """Attendre que les courses soient livrÃ©es"""
    print("ğŸ“¦ En attente de la livraison des ingrÃ©dients...")
    # Simulation: vÃ©rifier si le fichier de livraison existe
    import os
    return os.path.exists('/cuisine/livraison/ingredients.txt')

def verifier_temperature_four():
    """VÃ©rifier que le four est Ã  la bonne tempÃ©rature"""
    temperature_actuelle = 175  # Simulation
    temperature_cible = 180
    
    print(f"ğŸŒ¡ï¸  TempÃ©rature actuelle: {temperature_actuelle}Â°C")
    print(f"ğŸ¯ TempÃ©rature cible: {temperature_cible}Â°C")
    
    return temperature_actuelle >= temperature_cible

# Sensor pour attendre les ingrÃ©dients
sensor_ingredients = PythonSensor(
    task_id="attendre_ingredients",
    python_callable=attendre_livraison_ingredients,
    timeout=300,  # 5 minutes max d'attente
    mode="reschedule",  # LibÃ¨re le worker pendant l'attente
    poke_interval=30  # VÃ©rifie toutes les 30 secondes
)

# Sensor pour la tempÃ©rature du four
sensor_temperature = PythonSensor(
    task_id="verifier_temperature_four",
    python_callable=verifier_temperature_four,
    timeout=600,  # 10 minutes max
    mode="poke",  # Garde le worker occupÃ©
    poke_interval=10  # VÃ©rifie toutes les 10 secondes
)

def preparer_plat():
    """PrÃ©parer le plat une fois les conditions remplies"""
    print("ğŸ‘¨â€ğŸ³ Toutes les conditions sont remplies! Je commence la prÃ©paration...")

preparation = PythonOperator(
    task_id="preparer_plat",
    python_callable=preparer_plat
)

# DÃ©pendances: attendre les conditions AVANT de prÃ©parer
sensor_ingredients >> sensor_temperature >> preparation
```

### ğŸ”§ Code DÃ©taillÃ© avec Sensors AvancÃ©s
```python
from airflow.sensors.filesystem import FileSensor
from airflow.sensors.external_task import ExternalTaskSensor
from airflow.sensors.python import PythonSensor
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import requests
import json

# Sensor 1: Attendre un fichier de donnÃ©es
sensor_fichier_donnees = FileSensor(
    task_id="attendre_fichier_donnees",
    filepath="/data/incoming/daily_data.csv",
    timeout=3600,  # 1 heure max d'attente
    mode="reschedule",
    poke_interval=60,  # VÃ©rifie toutes les minutes
    soft_fail=False,  # Ã‰choue si timeout dÃ©passÃ©
    fs_conn_id="fs_default"  # Connection ID pour le systÃ¨me de fichiers
)

# Sensor 2: Attendre qu'un DAG externe soit terminÃ©
sensor_dag_externe = ExternalTaskSensor(
    task_id="attendre_dag_nettoyage",
    external_dag_id="data_cleaning_pipeline",
    external_task_id="fin_nettoyage",
    allowed_states=['success'],
    execution_delta=timedelta(hours=1),  # Attendre l'exÃ©cution d'il y a 1h
    timeout=7200,  # 2 heures max
    mode="reschedule",
    poke_interval=120  # VÃ©rifie toutes les 2 minutes
)

# Sensor 3: Condition personnalisÃ©e - API disponible
def verifier_api_disponible():
    """VÃ©rifie si l'API de donnÃ©es est disponible"""
    try:
        response = requests.get(
            'https://api.mon-service.com/health',
            timeout=10
        )
        if response.status_code == 200:
            health_data = response.json()
            return health_data.get('status') == 'healthy'
        return False
    except requests.exceptions.RequestException:
        return False

sensor_api = PythonSensor(
    task_id="verifier_api_disponible",
    python_callable=verifier_api_disponible,
    timeout=1800,  # 30 minutes max
    mode="poke",
    poke_interval=30  # VÃ©rifie toutes les 30 secondes
)

# Sensor 4: Attendre un certain nombre de fichiers
def verifier_fichiers_complets():
    """VÃ©rifie que tous les fichiers nÃ©cessaires sont prÃ©sents"""
    fichiers_requis = [
        '/data/incoming/clients.csv',
        '/data/incoming/produits.csv', 
        '/data/incoming/ventes.csv',
        '/data/incoming/config.json'
    ]
    
    fichiers_presents = []
    for fichier in fichiers_requis:
        try:
            with open(fichier, 'r'):
                fichiers_presents.append(fichier)
        except FileNotFoundError:
            print(f"â³ Fichier manquant: {fichier}")
    
    if len(fichiers_presents) == len(fichiers_requis):
        print("âœ… Tous les fichiers sont prÃ©sents!")
        return True
    else:
        print(f"ğŸ“ Fichiers prÃ©sents: {len(fichiers_presents)}/{len(fichiers_requis)}")
        return False

sensor_fichiers_multiple = PythonSensor(
    task_id="verifier_fichiers_complets",
    python_callable=verifier_fichiers_complets,
    timeout=3600,
    mode="reschedule", 
    poke_interval=60
)

# TÃ¢che de traitement principal
def traitement_principal(**context):
    """Traitement principal qui s'exÃ©cute une fois tous les sensors satisfaits"""
    execution_date = context['execution_date']
    print(f"ğŸš€ DÃ©but du traitement principal Ã  {execution_date}")
    
    # Logique de traitement...
    print("ğŸ“Š Traitement des donnÃ©es en cours...")
    
    return "traitement_termine"

traitement = PythonOperator(
    task_id="traitement_principal",
    python_callable=traitement_principal
)

# DÃ©pendances: Tous les sensors doivent Ãªtre satisfaits avant le traitement
[sensor_fichier_donnees, sensor_dag_externe, sensor_api, sensor_fichiers_multiple] >> traitement
```

---

## ğŸ¯ 6. BRANCHING - Prise de DÃ©cision

### ğŸ“š Explication DÃ©taillÃ©e
Le **Branching** permet de **choisir un chemin d'exÃ©cution** selon une condition. C'est comme dÃ©cider quelle recette faire selon les ingrÃ©dients disponibles.

**Fonctionnement :**
- `BranchPythonOperator` : Prend une dÃ©cision basÃ©e sur Python
- Retourne le `task_id` de la prochaine tÃ¢che Ã  exÃ©cuter
- Les autres branches sont ignorÃ©es

### ğŸ³ Illustration Culinaire
```python
from airflow.operators.python import BranchPythonOperator
from airflow.operators.dummy import DummyOperator

def choisir_recette_selon_saison(**context):
    """Choisit la recette selon la saison"""
    execution_date = context['execution_date']
    mois = execution_date.month
    
    # DÃ©terminer la saison
    if 3 <= mois <= 5:
        saison = "printemps"
        return "preparer_salade_printaniere"
    elif 6 <= mois <= 8:
        saison = "ete" 
        return "preparer_gazpacho"
    elif 9 <= mois <= 11:
        saison = "automne"
        return "preparer_soupe_citrouille"
    else:
        saison = "hiver"
        return "preparer_raclette"

def choisir_dessert_selon_ingredients():
    """Choisit le dessert selon les ingrÃ©dients disponibles"""
    ingredients_disponibles = ['chocolat', 'Å“ufs', 'farine', 'fruits']
    
    if 'chocolat' in ingredients_disponibles and 'Å“ufs' in ingredients_disponibles:
        return "preparer_fondant_chocolat"
    elif 'fruits' in ingredients_disponibles:
        return "preparer_salade_fruits"
    else:
        return "preparer_creme_dessert"

# TÃ¢che de dÃ©cision principale
choix_plat_principal = BranchPythonOperator(
    task_id="choisir_plat_principal",
    python_callable=choisir_recette_selon_saison
)

# TÃ¢che de dÃ©cision dessert
choix_dessert = BranchPythonOperator(
    task_id="choisir_dessert",
    python_callable=choisir_dessert_selon_ingredients
)

# TÃ¢ches pour les plats principaux
salade = DummyOperator(task_id="preparer_salade_printaniere")
gazpacho = DummyOperator(task_id="preparer_gazpacho")
soupe = DummyOperator(task_id="preparer_soupe_citrouille")
raclette = DummyOperator(task_id="preparer_raclette")

# TÃ¢ches pour les desserts
fondant = DummyOperator(task_id="preparer_fondant_chocolat")
salade_fruits = DummyOperator(task_id="preparer_salade_fruits")
creme = DummyOperator(task_id="preparer_creme_dessert")

# TÃ¢che de fin
fin = DummyOperator(task_id="service_repas")

# DÃ©pendances complexes
choix_plat_principal >> [salade, gazpacho, soupe, raclette]
[salade, gazpacho, soupe, raclette] >> choix_dessert
choix_dessert >> [fondant, salade_fruits, creme]
[fondant, salade_fruits, creme] >> fin
```

### ğŸ”§ Code DÃ©taillÃ© avec Branching Complexe
```python
from airflow.operators.python import BranchPythonOperator
from airflow.operators.python import PythonOperator
from airflow.operators.dummy import DummyOperator
from airflow.models import Variable

def analyser_qualite_donnees(**context):
    """Analyse la qualitÃ© des donnÃ©es et choisit le bon traitement"""
    try:
        # Simulation d'analyse de qualitÃ©
        execution_date = context['execution_date']
        fichier_source = f"/data/raw/{execution_date.strftime('%Y-%m-%d')}.csv"
        
        # MÃ©triques de qualitÃ© (simulÃ©es)
        metriques_qualite = {
            'completude': 0.85,  # 85% des donnÃ©es complÃ¨tes
            'exactitude': 0.92,  # 92% des donnÃ©es exactes
            'consistance': 0.78  # 78% des donnÃ©es consistantes
        }
        
        print(f"ğŸ“Š MÃ©triques de qualitÃ©: {metriques_qualite}")
        
        # Seuils de qualitÃ© configurables
        seuil_eleve = float(Variable.get("seuil_qualite_eleve", 0.9))
        seuil_moyen = float(Variable.get("seuil_qualite_moyen", 0.7))
        
        # DÃ©cision basÃ©e sur la qualitÃ©
        if metriques_qualite['completude'] >= seuil_eleve and metriques_qualite['exactitude'] >= seuil_eleve:
            return "traitement_automatique"
        elif metriques_qualite['completude'] >= seuil_moyen:
            return "traitement_avec_nettoyage"
        else:
            return "traitement_manuel_revision"
            
    except Exception as e:
        print(f"âŒ Erreur lors de l'analyse: {e}")
        return "traitement_erreur"

def choisir_methode_aggregation(**context):
    """Choisit la mÃ©thode d'agrÃ©gation selon le volume de donnÃ©es"""
    # RÃ©cupÃ©ration des mÃ©triques de la tÃ¢che prÃ©cÃ©dente
    metriques_qualite = context['ti'].xcom_pull(task_ids='analyser_qualite_donnees')
    
    volume_donnees = 500000  # Simulation
    
    if volume_donnees > 1000000:
        return "aggregation_distribuee"
    elif volume_donnees > 100000:
        return "aggregation_memoire"
    else:
        return "aggregation_simple"

# TÃ¢ches de dÃ©cision
decision_qualite = BranchPythonOperator(
    task_id="analyser_qualite_donnees",
    python_callable=analyser_qualite_donnees
)

decision_aggregation = BranchPythonOperator(
    task_id="choisir_methode_aggregation",
    python_callable=choisir_methode_aggregation
)

# TÃ¢ches de traitement selon la qualitÃ©
traitement_auto = PythonOperator(
    task_id="traitement_automatique",
    python_callable=lambda: print("ğŸ¤– Traitement automatique - haute qualitÃ©")
)

traitement_nettoyage = PythonOperator(
    task_id="traitement_avec_nettoyage",
    python_callable=lambda: print("ğŸ§¹ Traitement avec nettoyage - qualitÃ© moyenne")
)

traitement_manuel = PythonOperator(
    task_id="traitement_manuel_revision",
    python_callable=lambda: print("ğŸ‘¨â€ğŸ’» Traitement manuel - qualitÃ© faible")
)

traitement_erreur = PythonOperator(
    task_id="traitement_erreur",
    python_callable=lambda: print("ğŸš¨ Traitement d'erreur - donnÃ©es problÃ©matiques")
)

# TÃ¢ches d'agrÃ©gation
agg_distribuee = PythonOperator(
    task_id="aggregation_distribuee",
    python_callable=lambda: print("ğŸŒ AgrÃ©gation distribuÃ©e (Spark)")
)

agg_memoire = PythonOperator(
    task_id="aggregation_memoire",
    python_callable=lambda: print("ğŸ’¾ AgrÃ©gation en mÃ©moire (Pandas)")
)

agg_simple = PythonOperator(
    task_id="aggregation_simple",
    python_callable=lambda: print("ğŸ“Š AgrÃ©gation simple (SQL)")
)

# TÃ¢che finale
finalisation = PythonOperator(
    task_id="finaliser_traitement",
    python_callable=lambda: print("âœ… Traitement finalisÃ© avec succÃ¨s")
)

# DÃ‰PENDANCES COMPLEXES
# Premier niveau: dÃ©cision qualitÃ©
decision_qualite >> [traitement_auto, traitement_nettoyage, traitement_manuel, traitement_erreur]

# DeuxiÃ¨me niveau: dÃ©cision agrÃ©gation (sauf pour erreur)
[traitement_auto, traitement_nettoyage, traitement_manuel] >> decision_aggregation

# TroisiÃ¨me niveau: agrÃ©gation
decision_aggregation >> [agg_distribuee, agg_memoire, agg_simple]

# Niveau final: toutes les branches convergent
[agg_distribuee, agg_memoire, agg_simple, traitement_erreur] >> finalisation
```

---

## ğŸ¯ RÃ‰SUMÃ‰ GÃ‰NÃ‰RAL AIRFLOW

### **ğŸ—ï¸ Architecture Mentale**
```
DAG (Recette) 
    â†“
TASKS (Ã‰tapes)
    â†“  
DEPENDENCIES (Ordre)
    â†“
XCOM (Communication)
    â†“
SENSORS (Attentes) 
    â†“
BRANCHING (DÃ©cisions)
```

### **ğŸ“‹ Checklist de CrÃ©ation**
1. **DAG** : DÃ©finir le cadre (schedule, paramÃ¨tres)
2. **Tasks** : DÃ©composer en Ã©tapes unitaires  
3. **Dependencies** : Ordonner les Ã©tapes
4. **XCom** : Communiquer des donnÃ©es si nÃ©cessaire
5. **Sensors** : Ajouter des attentes si besoin
6. **Branching** : PrÃ©voir des dÃ©cisions conditionnelles

### **ğŸš¨ Bonnes Pratiques**
- **Idempotence** : Les tÃ¢ches peuvent Ãªtre rejouÃ©es
- **AtomicitÃ©** : Une tÃ¢che = une responsabilitÃ©
- **Monitoring** : Logs clairs et Ã©tats prÃ©cis
- **Gestion d'erreur** : Retries et alertes configurÃ©es

**Airflow transforme vos recettes data en plats gastronomiques bien orchestrÃ©s!** ğŸ½ï¸ğŸ‰